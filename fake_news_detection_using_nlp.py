# -*- coding: utf-8 -*-
"""Copy of fake news detection using NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y06e0FUAQ8rMh1FTZkUyfZmgNUqwwB7N
"""

!pip install pandas scikit-learn nltk

import pandas as pd
import numpy as np
import re
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

nltk.download('stopwords')
from nltk.corpus import stopwords

import kagglehub

# Download latest version
path = kagglehub.dataset_download("techykajal/fakereal-news")

print("Path to dataset files:", path)

# Load dataset from sample_data folder, specifying the encoding
df = pd.read_csv('/content/sample_data/New Task.csv', encoding='latin-1') # Try 'latin-1' or 'cp1252' if 'latin-1' doesn't work.

# Preview the first few rows
df.head()

df.columns

# Load dataset from sample_data folder, specifying the encoding
df = pd.read_csv('/content/sample_data/New Task.csv', encoding='latin-1') # Try 'latin-1' or 'cp1252' if 'latin-1' doesn't work.

# Preview the first few rows
df.head()

# Print the actual column names to identify the correct ones
print(df.columns)

# Check for null values and drop if any
# Replace 'text' and 'label' with the actual column names from the output above
df = df[['News_Headline', 'Link_Of_News', 'Source', 'Stated_On', 'Date',
       'Label']].dropna() # Assuming 'News_Headline' and 'News_Article' are your desired columns

# Optional: Shuffle the data to ensure random distribution
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

# Preview sample data
df.head()

# Rename the columns to 'text' and 'label' if needed
df = df.rename(columns={'News_Headline': 'text', 'News_Article': 'label'})

import re
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Function to clean each text
def clean_text(text):
    text = re.sub(r'\W', ' ', str(text))
    text = re.sub(r'\s+[a-zA-Z]\s+', ' ', text)
    text = re.sub(r'\^[a-zA-Z]\s+', ' ', text)
    text = re.sub(r'\s+', ' ', text, flags=re.I)
    text = re.sub(r'^b\s+', '', text)
    text = text.lower()
    return ' '.join([word for word in text.split() if word not in stop_words])

# Apply to dataset
df['clean_text'] = df['text'].apply(clean_text)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# Split the data
# Replace 'label' with 'Label' (the actual column name in your DataFrame)
X_train, X_test, y_train, y_test = train_test_split(
    df['clean_text'], df['Label'], test_size=0.2, random_state=42
)

# Convert text data to TF-IDF features
vectorizer = TfidfVectorizer(max_df=0.7)
tfidf_train = vectorizer.fit_transform(X_train)
tfidf_test = vectorizer.transform(X_test)

from sklearn.linear_model import PassiveAggressiveClassifier

# Train Passive Aggressive Classifier
model = PassiveAggressiveClassifier(max_iter=50)
model.fit(tfidf_train, y_train)

from sklearn.metrics import accuracy_score, confusion_matrix

# Predict on test data
y_pred = model.predict(tfidf_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {round(accuracy * 100, 2)}%")

# Confusion Matrix
# Get unique labels from y_test
unique_labels = np.unique(y_test)

# Print unique labels to see the actual values in your target variable
print("Unique labels in y_test:", unique_labels)

# Create confusion matrix using unique labels
conf_mat = confusion_matrix(y_test, y_pred, labels=unique_labels)
print("Confusion Matrix:\n", conf_mat)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(6, 4))
# Change 'label' to 'Label' to match the actual column name
sns.countplot(data=df, x='Label', palette='Set2')
plt.title('Distribution of Real vs Fake News')
plt.xlabel('News Type')
plt.ylabel('Count')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Correct the column name to 'Label'
sns.countplot(data=df, x='Label', palette='Set2')
plt.title('Distribution of Real vs Fake News')
plt.xlabel('News Type')
plt.ylabel('Count')
plt.xticks(rotation=45)  # Rotate x-axis labels
plt.tight_layout()       # Adjust layout to prevent cutoff
plt.show()

# Get the unique labels from your target variable (y_test or y_train)
unique_labels = np.unique(y_test)

# Create the DataFrame for the confusion matrix using the unique labels
conf_df = pd.DataFrame(conf_mat, index=unique_labels, columns=unique_labels)

# Continue with your heatmap plotting code
plt.figure(figsize=(6, 5))
sns.heatmap(conf_df, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix Heatmap')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

def show_top_words(vectorizer, model, class_label, top_n=20):
    feature_names = vectorizer.get_feature_names_out()
    # Get the actual class labels from the model
    class_labels = model.classes_
    # Check if the provided class_label is in the model's classes
    if class_label in class_labels:
        class_index = list(class_labels).index(class_label)
        top_indices = model.coef_[class_index].argsort()[::-1][:top_n]
        top_features = [feature_names[i] for i in top_indices]
        top_scores = model.coef_[class_index][top_indices]

        plt.figure(figsize=(8, 4))
        sns.barplot(x=top_scores, y=top_features, palette='coolwarm')
        plt.title(f"Top {top_n} Words for {class_label} News")
        plt.xlabel("Importance")
        plt.show()
    else:
        print(f"Class label '{class_label}' not found in model classes: {class_labels}")

# Show for FAKE and REAL (or the actual labels in your dataset)
# Print the model's classes to check the actual labels
print("Model classes:", model.classes_)

# Call show_top_words with the correct class labels
# For example, if your labels are 'fake' and 'real', use:
show_top_words(vectorizer, model, model.classes_[0])  # Assuming 'fake' is the first class
show_top_words(vectorizer, model, model.classes_[1])  # Assuming 'real' is the second class
